# 1. 协程的理解

+ 协程是：协程只是程序调度的方式，多线程和多进程由操作系统调度，而协程由程序自身即程序员调度，仅此而已。
+ 协程的作用：实现异步 IO，异步 IO 指的是程序只发 IO 指令并不阻塞等待 IO 结果，在 IO 结束前需要 IO 结果的代码当然不能执行，所以我们通过协程调度，然后让 CPU 去执行别的代码，等 IO 结束再切换回来，其实就只是增加 CPU 的利用率。 IO 不是 CPU 在干活，而是磁盘、网络之类，正是因为 CPU 的速度远高于磁盘及网络，所以我们通过异步的方式来进行 IO 操作，就是 IO 的时候不让 CPU 傻站着等， IO 结束后，需要 IO 结果的代码需要接着执行，所以需要使用协程切换回来，协程只是可以让程序在某个地方停下来，然后在需要的时候( IO 完成后)再接着执行。

# 2. 协程和多线程之间的区别

## 2.1 多线程

+ python多线程有个全局解释器锁（global interpreter lock），这个锁的作用是：任一时间只能有一个线程使用解释器，跟单 CPU 跑多个程序一个意思，大家都是轮着用的，这叫“并发”，不是“并行”。
+ python中的多线程也只是 CPU 并发执行多条线程，某一短暂的时间内只执行一条线程，然后再切换另一条线程执行，速度很快， CPU 基本没歇着。

## 2.2 协程

+ 协程，虽说是一条线程，但也实现了各代码块的快速交替执行， CPU 基本也没歇着。而多线程与协程相比，一是需要 CPU 为线程间的切换分配精力，二是多线程有资源竞争的风险。

# 3. 线程与进程

## 概念

线程：是程序执行流的最小单元，是系统独立调度和分配CPU（独立运行）的基本单位。

进程：是资源分配的基本单位。一个进程包括多个线程。

## 区别

1. 线程与资源分配无关，它属于某一个进程，并与进程内的其他线程一起共享进程的资源。
2. 每个进程都有自己一套独立的资源（数据），供其内的所有线程共享。
3. 不论是大小，开销线程要更“轻量级”
4. 一个进程内的线程通信比进程之间的通信更快速，有效。（因为共享变量）

# 4. 多线程与多进程

## 概念

+ 多线程：一个程序同时执行多个线程。如，用浏览器一边下载，一边听歌，一边看视频，一边看网页......
+ 多进程：同时执行多个程序。如，同时运行YY，QQ，以及各种浏览器。

## 区别

- 共享资源的方式不同：
  - 多线程：多线程可以使用全局变量、参数传递的方式共享进程内的资源
  - 多进程：多进程应该避免共享资源，因为每个进程都有自己独立的内存空间。可以通过共享内存和 Manager 的方法来共享资源，但这样做提高了程序复杂度，并且因为同步的需要降低了程序执行的效率。

## 并发与并行

+ 并发：当有多个线程在操作时, 如果系统只有一个CPU, 则它根本不可能真正同时进行一个以上的线程，它只能把CPU运行时间划分成若干个时间段,再将时间段分配给各个线程执行，在一个时间段的线程代码运行时，其它线程处于挂起状态。这种方式我们称之为并发(Concurrent)。
+ 并行：当系统有一个以上CPU时,则线程的操作有可能非并发。当一个CPU执行一个线程时，另一个CPU可以执行另一个线程，两个线程互不抢占CPU资源，可以同时进行，这种方式我们称之为并行(Parallel)。

## 注意

+ 多核，多cup，多机是不同的概念。

## 4.1 多线程的使用

### 使用 threading 模块

+ ```python
  # threading.Thread类参数简介
  class threading.Thread(group=None, target=None, name=None, args=(), kwargs={}, *, daemon=None)
  
  '''
  group：目前此参数为None，在实现ThreadGroup类时为将来的扩展保留。
  target：target接收的是一个函数的地址，由run()方法调用执行函数中的内容。默认为无，表示未调用任何内容。
  name ：线程名，可自行定义。
  args：target接收的是函数名，此函数的位置参数以元组的形式存放在args中，用于执行函数时调用。
  kwargs ：target接收的是函数名，此函数的关键字参数以字典的形式存放在kwargs中，用于执行函数时调用。
  daemon：如果为True表示该线程为守护线程。
  '''
  
  # threading.Thread类的常用方法
  
  '''
  start()：开启线程，一个Thread对象只能调用一次start()方法，如果在同一线程对象上多次调用此方法，则会引发RuntimeError。
  
  run()：执行start()方法会调用run()，该方将创建Thread对象时传递给target的函数名，和传递给args、kwargs的参数组合成一个完整的函数，并执行该函数。run()方法一般在自定义Thead类时会用到。
  
  join(timeout=None)：join会阻塞、等待线程，timeout单位为秒，因为join（）总是返回none，所以在设置timeout调用join（timeout）之后，需要使用isalive（）判断线程是否执行完成，如果isalive为True表示线程在规定时间内没有执行完，线程超时。如果join(timeout=None)则会等待线程执行完毕后才会执行join（）后面的代码，一般用于等待线程结束。
  
  name：获取线程名。
  getName()：获取线程名。
  setName(name)：设置线程名。
  ident：“线程标识符”，如果线程尚未启动，则为None。如果线程启动是一个非零整数。
  is_alive()：判断线程的存活状态，在run（）方法开始之前，直到run（）方法终止之后。如果线程存活返回True，否则返回False。
  daemon：如果thread.daemon=True表示该线程为守护线程，必须在调用Start（）之前设置此项，否则将引发RuntimeError。默认为False
  isDaemon()：判断一个线程是否是守护线程。
  setDaemon(daemonic)：设置线程为守护线程。
  '''
  ```

#### 示例1：开启单个线程

+ ```python
  from threading import Thread
  import threading
  import time
  
  
  def song(a,b,c):
      print(a, b, c)
      for i in range(5):
          print("song")
          time.sleep(1)
  
  def thread_work(count):
      print(f"第 {count} 个线程程正在执行")
  
  
  if __name__ == "__main__":
      # 1、使用元组传递 threading.Thread(target=方法名，args=（参数1,参数2, ...）)
      thread = Thread(target=thread_work, args=(1,), name='我是线程demo')
      thread.start()
  
      # 2、使用字典传递 threading.Thread(target=方法名, kwargs={"参数名": 参数1, "参数名": 参数2, ...})
      # Thread(target=song, kwargs={"a": 1, "c": 3, "b": 2}).start()  # 参数顺序可以变
  
      # 3、混合使用元组和字典 threading.Thread(target=方法名，args=（参数1, 参数2, ...）, kwargs={"参数名": 参数1,"参数名": 参数2, ...})
      # Thread(target=song, args=(1,), kwargs={"c": 3, "b": 2}).start()
  ```

#### 示例2：开启多个线程

+ ```python
  from threading import Thread
  import time
  
  
  def thread_work(count):
      time.sleep(1)
      print(f"第 {count} 个线程正在执行")
  
  
  if __name__ == '__main__':
      print('主线程')
  
      start = time.time()
  
      thread_list = []
      for i in range(5):
          t = Thread(target=thread_work, args=(i,))
          t.start()
          thread_list.append(t)
  
      for thread in thread_list:
          thread.join()
  
      end = time.time()
  
      print(f'线程一共运行了: {end - start:0.2f} s')
      
      
  # output
  '''
  主线程
  第 4 个线程正在执行第 2 个线程正在执行
  第 0 个线程正在执行
  第 3 个线程正在执行
  
  第 1 个线程正在执行
  线程一共运行了: 1.01 s
  '''
  ```

+ 

### 使用 ThreadPoolExecutor 线程池对象

+ ```python
  from concurrent.futures import ThreadPoolExecutor
  
  class concurrent.futures.ThreadPoolExecutor(max_workers=None, thread_name_prefix='', initializer=None, initargs=())：
  
  # max_workers：线程池的数量。
  # thread_name_prefix：线程名前缀。默认线程名ThreadPoolExecutor-线程数。
  # initializer：一个函数或方法，在启用线程前会调用这个函数（给线程池添加额外任务）。
  # initargs ：以元组的方式给initializer中的函数传递参数。
  ```

#### 示例1：使用参数 initializer 添加额外任务

+ ```python
  from concurrent.futures import ThreadPoolExecutor
  def work():
      print('工作线程')
  def test(num):
      print('test:',num)
  executor = ThreadPoolExecutor(max_workers=2, initializer=test(7))  # 开启2个线程  initializer指定参数test(7)
  executor.submit(work)  
  executor.submit(work)
  
  '''
  # 打印内容如下
  test: 7
  工作线程
  工作线程
  '''
  ```

#### 示例2：使用参数 initargs 给 initializer  调用的函数传参

+ ```python
  from concurrent.futures import ThreadPoolExecutor
  def work():
      print('工作线程')
  def test(num):
      print('test:',num)
  executor = ThreadPoolExecutor(max_workers=2, initializer=test, initargs=(7,)) # 这里我们使用initargs=(7,)的方式给test传递参数。
  executor.submit(work)
  executor.submit(work)
  
  '''
  # 打印内容如下
  test: 7
  工作线程
  工作线程
  test: 7
  '''
  ```

#### 示例3：循环提交多个子线程给线程池

+ ```python
  from concurrent.futures import ThreadPoolExecutor
  import time
  
  
  def work(num):
      time.sleep(1)
      print('工作线程:',num)
      
      
  if __name__ == '__main__':
      executor = ThreadPoolExecutor(max_workers=5)  # 创建线程池，数量为5
      for i in range(5):
          executor.submit(work, i)
      # 使用shutdown等待所有线程结束后在打印主线程
      executor.shutdown(wait=True)  # 等待线程池结束
      print('主线程')
  
  # 打印内容如下
  '''
  工作线程: 0
  工作线程: 1
  工作线程: 2
  工作线程: 3
  工作线程: 4
  主线程
  '''
  ```

## 4.2 多进程的使用

### 使用 multiprocessing  模块

#### 示例1：开启单个进程

+ ```python
  from multiprocessing import Process
  
  
  def process_work(count):
      print(f"第 {count} 个进程正在执行")
  
  
  if __name__ == '__main__':
      print('我是主进程')
  
      pro = Process(target=process_work, args=(1,), name='我是进程demo')
      pro.start()
  ```

#### 示例2：开启多个进程

+ ```python
  from multiprocessing import Process
  import time
  
  
  def process_work(count):
      time.sleep(1)
      print(f"第 {count} 个进程正在执行")
  
  
  if __name__ == '__main__':
      print('我是主进程')
  
      start = time.time()
  
      process_list = []
      for i in range(5):
          p = Process(target=process_work, args=(i,))
          p.start()
          process_list.append(p)
  
      for p in process_list:
          p.join()
  
      end = time.time()
  
      print(f'进程运行了: {end-start:0.2f} s')
      
  
  # output
  '''
  我是主进程
  第 0 个进程正在执行
  第 1 个进程正在执行第 2 个进程正在执行第 3 个进程正在执行第 4 个进程正在执行
  
  
  
  进程运行了: 1.13 s
  '''
  ```

### 使用 ProcessPoolExecutor 进程池对象

+ ```python
  class concurrent.futures.ProcessPoolExecutor(max_workers=None, mp_context=None, initializer=None, initargs=())
  
  # max_workers：工作进程数。如果 max_workers 为 None 或未给出，它将默认为机器的处理器个数。 如果 max_workers 小于等于 0，则将引发 ValueError。 在 Windows 上，max_workers 必须小于等于 61，否则将引发 ValueError。 如果 max_workers 为 None，则所选择的默认最多为 61，即使存在更多处理器。
  
  # mp_context ：可以是一个多进程上下文或是 None。 它将被用来启动工作进程。 如果 mp_context 为 None 或未给出，将使用默认的多进程上下文。
  
  # initializer：一个函数或方法，在启用进程前会调用这个函数。
  # initargs ：以元组的方式给initializer中的函数传递参数。
  ```

#### 示例1：循环提交多个子进程给进程池

+ ```python
  from concurrent.futures import ProcessPoolExecutor
  import time
  
  
  def work(num):
      time.sleep(1)
      print('工作进程:',num)
      
      
  if __name__ == '__main__':
      executor = ProcessPoolExecutor(max_workers=5)  # 创建进程池，数量为5
      for i in range(5):
          executor.submit(work, i)
          
      # 使用shutdown等待所有线程结束后在打印主线程
      executor.shutdown(wait=True)
      print('主线程')
      
  '''
  # 打印内容如下
  工作进程: 0
  工作进程: 1
  工作进程: 2
  工作进程: 3
  工作进程: 4
  主线程
  '''
  ```

#### 示例2：如果想要在线程执行的过程中添加额外的功能，可以使用initializer参数

+ ```python
  from concurrent.futures import ProcessPoolExecutor
  
  
  def work(num):
      print('工作进程:',num)
      
  def test(num):
      print('额外任务:',num)
      
      
  if __name__ == '__main__':
      executor = ProcessPoolExecutor(max_workers=5,initializer=test,initargs=(7,)) # 添加额外任务
      for i in range(5):
          executor.submit(work, i)
      executor.shutdown(wait=True)
      print('主线程')
      
  
  # 打印内容如下
  '''
  额外任务: 7
  工作进程: 0
  工作进程: 1
  工作进程: 2
  工作进程: 3
  工作进程: 4
  额外任务: 7
  额外任务: 7
  额外任务: 7
  额外任务: 7
  主线程
  '''
  ```

## 4.3 多进程和多线程的效率对比

+ 我们可以从时间上看出，线程的效率是远远高于进程的。

+ ```python
  from threading import Thread
  from multiprocessing import Process
  import time
  
  
  def process_work(count):
      print(f"第 {count} 个进程正在执行")
  
  
  def thread_work(count):
      print(f"第 {count} 个进程正在执行")
  
  
  if __name__ == '__main__':
      # 线程执行效率
      start = time.time()
      thread_list = []
      for i in range(5):
          t = Thread(target=thread_work, args=(i,))
          t.start()
          thread_list.append(t)
  
      for thread in thread_list:
          thread.join()
      end = time.time()
      print(f'线程一共运行了: {end - start:0.6f} s')
  
      # 进程执行效率
      start = time.time()
  
      process_list = []
      for i in range(5):
          p = Process(target=process_work, args=(i,))
          p.start()
          process_list.append(p)
  
      for p in process_list:
          p.join()
  
      end = time.time()
  
      print(f'进程运行了: {end-start:0.6f} s')
      
  # output
  '''
  第 0 个进程正在执行
  第 1 个进程正在执行
  第 2 个进程正在执行
  第 3 个进程正在执行
  第 4 个进程正在执行
  线程一共运行了: 0.001958 s
  第 0 个进程正在执行
  第 1 个进程正在执行
  第 2 个进程正在执行
  第 4 个进程正在执行
  第 3 个进程正在执行
  进程运行了: 0.113299 s
  
  '''
  ```

# 5. 守护线程与守护进程

## 5.1 守护线程

+ 主线程会等待所有非守护线程执行完毕后，才结束主线程
+ 守护线程会等待主线程的结束而结束。这是因为如果主线程结束意味着程序结束，主线程会一直等着所有非守护线程结束，回收资源然后退出程序，所以当所有非守护线程结束后，守护线程结束，然后主线程回收资源，结束程序。

### 示例1：守护线程

+ ```python
  from threading import Thread
  
  def thread_work(name):
      print(name)
  
  if __name__ == "__main__":
      t = Thread(target=thread_work,args=("守护线程",))
      t.daemon=True
      t.start()
      print("\n主线程")
  
  # 打印内容如下
  '''
  守护线程
  主线程
  '''
  ```

+ 也许你会说是由于线程太快了，所以才执行了守护线程。下面我们在线程中阻塞一段时间，在来看看会发生什么效果。

### 示例2：阻塞守护线程

+ ```python
  from threading import Thread
  import time
  def thread_work(name):
      time.sleep(3)  # 阻塞3秒
      print(name)
  
  if __name__ == "__main__":
      t = Thread(target=thread_work,args=("守护线程",))
      t.daemon=True
      t.start()
      print("\n主线程")
  
  # 打印内容如下
  '''
  主线程
  守护线程
  '''
  ```

+ 守护线程还是被执行了，如果是守护进程，守护进程里的代码是不会被执行的。

## 5.2 守护进程

+ 主进程是进程内的代码结束后就结束主进程，不会管守护进程是否执行完毕。
+ 主进程会在代码执行完毕后立即关闭守护进程，因为在主进程看来代码执行完毕，主进程结束了，所以守护进程在代码结束后就被结束了。

## 示例：守护进程

+ ```python
  from multiprocessing import Process
  
  def process_work(name):
      print(f"{name}")
  
  if __name__ == "__main__":
      p = Process(target=process_work,args=("守护进程"))
      p.daemon=True
      p.start()
      print("主进程")
  
  # 打印内容如下
  '''
  主进程
  '''
  ```

+ 只打印了主进程，也就是说守护进程还没来得及执行程序就结束了。

# 6.锁

## 6.1 线程锁 Lock

### 概念

+ Lock也称线程同步锁，互斥锁，原子锁，该对象只有两个方法。

### Lock 对象的方法

+ **acquire(blocking=True, timeout=-1)：**加锁

  + 参数

  + blocking：当为True时表示加锁，只允许一个线程执行被加锁的代码。直到遇到release()解锁后其它线程才可以执行加锁部分的代码。当为False时表示不加锁，并且不能调用release()否则会报 RuntimeError。

    timeout：设置加锁时间，单位为秒。-1表示一直等待线程release()后，才允许其它线程执行加锁的代码。

+ **release()：**释放锁。

### 示例1：未加锁的线程

+ ```python
  from threading import Thread
  import time
  
  def work():
      global n
      temp = n
      time.sleep(0.1)  # 由于线程太快了，所以这里停顿下
      n = temp -1
  
  if __name__ == "__main__":
      n = 100
      t_l = []
      for i in range(100):
          t = Thread(target=work,args=())
          t.start()
          t_l.append(t)
      for i in t_l:
          i.join()
      print(n)
  
  # 打印内容如下
  99
  ```

+ 在我们看来其实值应该是0的但却是99，就因为短暂停了0.1秒导致结果发生了变化。而我们这0.1秒的停留是模拟网络延迟或者进程调度等原因。造成了数据的结果的错乱。这个时候我们就需要线程锁来保证数据的安全性。

### 示例2：过给线程加锁，来保证数据的安全性

+ ```python
  from threading import Thread,Lock
  import time
  
  def work(lock):
      lock.acquire()  # 加锁
      global n
      temp = n
      time.sleep(0.1)  # 由于线程太快了，所以这里停顿下
      n = temp -1
      lock.release()  # 解锁
  
  if __name__ == "__main__":
      n = 100
      t_l = []
      lock = Lock()  # 得到一把锁对象
      for i in range(100):
          t = Thread(target=work,args=(lock,))
          t.start()
          t_l.append(t)
      for i in t_l:
          i.join()
      print(n)
  
  # 打印内容如下
  0
  ```

+ 我们会发现程序和上一个示例的运行效率上有着很大的差别。明显加锁后程序的运行效率降低了，我们管这种锁叫做线程同步锁，使原本并行的程序编程了串行所以程序的效率会慢很多，但是程序的运行结果是正确的。在程序的运行效率和数据的正确性，我们应首先确保程序的正确性然后在考虑程序的效率。

## 6.2 递归锁 RLock

### 死锁

+ 所谓死锁： 是指两个或两个以上的进程或线程在执行过程中，出现了一种互相等待的情况，它们都将无法进行下去。此时称系统处于死锁状态或系统产生了死锁，这些永远在互相等待的进程称为死锁进程。

#### 示例：模拟产生死锁

+ ```python
  from threading import Lock,Thread
  
  def work():
      # 获取锁
      lock.acquire()
      print("我是工作线程 1")
      # 释放锁
      lock.release()
  
  def work_2():
      # 获取锁
      lock.acquire()
      print("我是工作线程 2")
      work()  # 调用工作线程1，造成死锁
      # 释放锁
      lock.release()
  
  if __name__ == '__main__':
      # 生成lock实例
      lock = Lock()
      # 开始3个线程
      for i in range(3):
          t = Thread(target=work_2)
          t.start()
      print('我是主线程')
  
  # 打印内容如下
  '''
  我是主线程
  我是工作线程 2  # 此时程序处于死锁状态
  '''
  ```

+ 我们可以理解为一把锁对象只能创建一把锁，这把锁必须release后，才能再次使用。否则程序就会被锁住，等待解锁。如上面的代码，work_2执行创建一个lock锁，调用work又遇到一把lock锁，而在work_2中的lock锁没有被解锁，所以程序在work中等待lock解锁，最终造成了程序出现了死锁

### 递归锁

+ 使用 递归锁 RLock 可以避免死锁

#### 示例：使用RLock避免死锁

+ ```python
  from threading import RLock,Thread
  
  def work():
      # 获取锁
      lock.acquire()
      print("我是工作线程 1")
      # 释放锁
      lock.release()
  
  def work_2():
      # 获取锁
      lock.acquire()
      print("我是工作线程 2")
      work()  # 调用工作线程1，造成死锁
      # 释放锁
      lock.release()
  
  if __name__ == '__main__':
      # 使用递归锁RLock
      lock = RLock()
      # 开始3个线程
      for i in range(3):
          t = Thread(target=work_2)
          t.start()
      print('我是主线程')
  
  # 打印内容如下
  我是工作线程 2
  我是工作线程 1
  我是工作线程 2
  我是工作线程 1
  我是工作线程 2
  我是主线程
  我是工作线程 1
  ```